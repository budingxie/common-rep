HashMap：
    常问：1.7头插法；1.8尾插法；1.7就是把链表头部元素放在新数组里面，然后再放next。尾部插入就先把最后的节点放入。
    头插法：创建一个新数组，容量为旧容量的两倍。然后遍历table，e.next = newTable[i];  newTable[i] = e;
    尾插法：创建一个新数组，容量为旧容量的两倍。然后 table = newTab; 现在table中都是空的。当 newTab[i] = e

	1.hashMap是key-value形式的散列集合，允许空值和空键，无序、散列表，。jdk1.8之前采用 数组+链表实现，存储的是Node元素。jdk1.8以及之后采用的是 数组+链表+红黑树

	2.在hashMap初始化的时候，有两个重要参数：初始化容量(默认16)，装载因子(默认0.75)。容量是表示数组的长度，当hashMap中的条目数超过 装载因子 * 容量的时候，就会进行扩容。新容量变成原来的两倍。
	
	3.put：检查table数组是否为null(为null进行初始化)，通过key的 (hashCode值 ^ (hashCode值>>>16) 得到的hash值) 和(容量-1)进行 & 操作，找到对应的数组下标。如果对应位置不存在节点，放入节点，最后判断元素的个数size和阈值进行的大小，检查是否需要扩容。如果对应位置存在节点，先检查是否是同一个key(先判断key==，再判断equals)，是的话覆盖旧值；不是的话，再判断该位置的节点是否是 TreeNode(树的插入，或者替换)。都不是的话(Node链表)，进行插入或者替换，再判断链表中节点的个数(大于8个)，如果大于(再判断容量和64比较，决定是扩容，还是转成树)。最后if (++size > threshold)是否扩容(可能造成树退化成链表)，找到最后面一段位置变动相同的头节点。
	
	4.get：通过key的 (hashCode值 ^ (hashCode值>>>16) 得到的hash值) 和(容量-1)进行 & 操作，找到对应的数组下标，拿到对应的Node检查Node的key是否和传入的一致(==,equals)是就返回。不是，再检查当前节点Node是否是TreeNode(是，进行树的查找)。否则就是链表查找。
	

ConcurrentHashMap：
	1.相当于HashMap的多线程实现，
		compareAndSwapInt方法：
			参数：
			1.当前实例
			2.实例变量的内存地址偏移量
			3.预期的旧值
			4.要更新的新值
		compareAndSwapObject方法
			参数：
			1.当前实例
			2.实例变量的内存地址偏移量
			3.预期的旧值
			4.要更新的新值
	
	2.put：检查table数组是否为null(为null进行初始化，通过compareAndSwapInt方法把sizeCtl修改为-1，初始化table数组，再把sizeCtl修改为12(容量-容量>>>2) )，通过key的 (hashCode值 ^ (hashCode值>>>16) 得到的hash值) 和(容量-1)进行 & 操作，找到对应的数组下标。获取到下标位置的元素检查是否为null，如果为null，然后通过compareAndSwapObject修改对应内存地址上的值(修改成功break，失败的话说明其他线程在操作，再次自旋)。对应位置Node不为null，获取hash值和-1比较(等于，帮助扩容helpTransfer方法)。不等于，加入同步代码块(synchronized锁住头元素--table里面的元素)，在通过tabAt()获取头元素(读这个操作保证了可见性，从硬件层面说，就是加了load屏障。)，查看是否等于 synchronized锁住的头元素(双重检查)，后面就会hashMap里面的添加差不多了(添加、更新(key相同)元素到链表、到树、或者扩容)。就是树节点变成了TreeBin。
	
	3.get：和HashMap没什么区别，就是获取头元素的时候采用了，tabAt()获取头元素(读这个操作保证了可见性，从硬件层面说，就是加了load屏障。)。
	
	
CAS锁：比较交换，java里面通过unsafe类去实现调用，是cpu上的原子指令，实现方式基于硬件平台的汇编指令。cpu通过 总线锁、缓存锁 来保证原子性。

AQS锁：aqs是AbstractQueuedSynchronizer抽象类相当于一个模板类，提供一个先进先出等待队列的阻塞锁和相关同步器。具体实现有 ReentrantLock、Semaphore、ReentrantReadWriteLock、CountDownLatch。
	属性：
	    Node head
	    Node tail

	举例：
	ReentrantLock里面的FairSync(公平同步)、NonfairSync(非公平同步锁，默认使用)，

	Node 节点属性：
	    pre
	    next
	    waitStatus
	    thread

	形成的样子
	AQS
	head(pre->自己) --> Node --> Node <---tail(next->null)
	                        <--


	lock()：方法获取锁
	使用compareAndSetState将state修改为1，成功相当于获取到锁，并且设置锁拥有线程为当前线程。修改1失败，再次尝试tryAcquire(1)(可能修改的失败之后的一瞬间，有锁释放，所以再次调用tryAcquire(1)进行尝试，但是会先判断state是否为0)；公平下：查看有其他线程比我等待时间长吗(长，就不再尝试修改state)?；非公平下，再次尝试修改state。如果都没成功，然后调用acquireQueued方法，再调addWaiter加入同步队列(cas原子操作)。后面操作就是acquireQueued方法进行，自旋获取prev节点，判断是否是head节点，不是则park(操作系统上的阻塞)；是头节点，再次尝试修改state，如果修改不成功，则进行头节点.prev还是自己，再次自旋修改状态state。
	
	unlock()：释放锁。
	没有公平、非公平之分。对当前state进行 减一 ，然后判断state是否为0，是则，把锁的拥有者线程设置为null，返回true，进行唤醒头节点的next，unPark head的next操作；不为0，说明拥有锁的线程加了多次锁，这个时候次数减一了，但是锁的拥有线程不设置为null，且返回false。
	
线程池：new ThreadPoolExecutor(int corePoolSize,
                                     int maximumPoolSize,
                                     long keepAliveTime,
                                     TimeUnit unit,
                                     BlockingQueue<Runnable> workQueue,
                                     ThreadFactory threadFactory,
                                     RejectedExecutionHandler handler);
        allowCoreThreadTimeOut(true)：设置是否允许核心线程超时。

	相对于自己创建线程的优势：
	1.降低线程创建和销毁的线程的资源消耗，提高了响应速度(免去了创建、销毁时间)
	2.统一管理的线程
	
	执行流程：
	1.当一个任务提交时
	2.如果当前执行线程数小于核心线程数，就创建新线程开始执行任务。
	3.如果当前执行线程数不小于核心线程数，把当前任务加入任务队列。
	4.如果当前执行线程数 >= 核心线程数，且 任务队列也满了。再看最大线程数，小于 则创建新线程执行任务。
	5.当前执行线程数 >= 核心线程数，且 任务队列也满了 且 当前线程 == 最大线程数，执行拒绝策略。
	
	拒绝策略：
	线程里面提供的
	1.AbortPolicy：抛出异常(RejectedExecutionException)
	2.DiscardPolicy：直接丢弃任务
	3.DiscardOldestPolicy：丢弃任务队列中比较久的任务
	4.CallerRunsPolicy：使用调用者线程执行
	还可以实现：RejectedExecutionHandler接口进行自定义的拒绝策略
	
	参数解析：
	corePoolSize：保留在池中的线程数，即使它们处于空闲状态。除非设置了allowCoreThreadTimeOut为true。
	maximumPoolSize：池中允许的最大线程数。
	keepAliceTime：当线程数大于核心线程数时，这时候空闲的线程，将在终止前等待新任务的最长存活时间。
	unit：keepAliveTime参数的时间单位。
	workQueue：在执行任务之前用于保留任务的队列。
	threadFactory：线程创建的工厂。
	handler：线程到达最大，任务队列也满了。进行的拒绝处理。

	线程池问题：
	1.使用execute和submit提交任务，如果出现异常，会出现什么情况？
	答：execute执行会直接抛出异常；submit则不会抛出异常，只有在调用get方法获取结果的时候，会抛出。原因，submit执行任务，会将异常捕获，然后放在返回值里面。在调用get获取返回值的时候，判断是否是异常类型，然后抛出。

代理：jdk、cglib
	jdk代理：
	基于反射机制，生成一个实现代理接口的匿名类，然后重写方法，实现方法的增强。
	cglib代理：
	基于继承机制，继承被代理类，所以方法不要申明为final，然后重写父类方法到达增强了类的效果。
	
	性能差异：
	jdk基于反射、cglib基于字节码。第一次生成字节码时间比较长，而多次调用反射也耗时。
	反射调用的次数达到阈值[也就是反射调用的类成为热点时]之后采用字节码的方式。
	
JVM：
	运行时内存区域：
	堆：分为 新生代、老年代。
		新生代：分为 Eden、Survivor(from to) 占比8：1：1。在GC开始的时候，Eden区的存活的对象，会向to(空)进行复制，然而在from区域的会判断，年龄大小和是否要回收。如果年龄不到，复制到to区。然后gc清除所有不存活的对象。而From区则清空，这时from 和to交换身份。所以不管怎样，都保证to区为空。
		老年代：存放生命周期较长的对象。
		
		担保机制：
		当新对象创建，而新生代区放不下，执行担保，把存在新生代的对象放在老年代，为新对象提供空间。不同的垃圾回收器有所不同。
		Minor GC 清理新生代。 Major GC 清理永久代。Full GC 清理整个堆区
	虚拟机栈：线程私有内存区域。
		在方法加入到栈里面进行执行时，会被打成一个栈帧，包括：局部变量表、操作数栈、动态连接、方法出口。
	本地方法栈：
		
	
	方法区：
		java文件编译后（javac），就会形成一份class文件；class文件中包括类的版本、字段、方法、接口等描述信息外，还有一项就是常量池(class文件常量池、运行时常量池)。
		class文件常量池：存放编译器生成的各种字面量和符号引用。
		运行时常量池：JVM在执行某个类的时候，必须经过加载、连接、初始化。而连接又包括验证、准备、解析三阶段。当类加载到内存中后，jvm就会将class常量池中的内容存放到运行时常量池中。运行时常量池也是每个类都有的一个。在解析阶段，会把符号引用替换为直接引用。
	程序计数器：
		程序计数器是当前线程正在执行的字节码的地址。程序计数器是线程隔离的，每一个线程在工作的时候都有一个独立的计数器。
	
	双亲委派模型：
	类加载器：
		Bootstrap：加载java_home/lib下的类
		Extension：加载java_home/lib/ext下的类
		Application：自己开发的类

    常说：某个类加载器不能加载 该类时，给父类加载器(这个父类加载器不是通过继承的形式，类似与 类加载器里面有个   属性为parent 引用 高级别的类加载器)
    例子：Application类加载器 里面有个  parent属性 是Extension类加载器。

	判断一个类是否唯一：类加载器和类本身。

	对象布局；对应到jvm中运行时数据区的关系
	一个对象被创建在堆中，对象的结构是：
	1.对象头(8byte或者16byte-->32位和64位操作系统)
	    1.mark word(4字节或者8字节-->32位和64位操作系统)：用于记录锁状态和拥有者，以及年龄和gc标记
	        32位：
	        前25位是对象的HashCode
	        后4位是对象的分代年龄
	        后2位是锁标志位
	        最后1位固定为0
	        32 bits:
              --------
              hash:25 ------------>| age:4    biased_lock:1 lock:2 (normal object)
              JavaThread*:23 epoch:2 age:4    biased_lock:1 lock:2 (biased object)
              size:32 ------------------------------------------>| (CMS free block)
              PromotedObject*:29 ---------->| promo_bits:3 ----->| (CMS promoted object)

	        64位：
	        前25位unused(没有使用)
	        后31位是对象的HashCode
	        后1位cms_free：和cms收集器有关、因为cms算法是标记-清理，内存碎片问题是将不可达对象委会在一个列表free list中，标记是否在列表中。
	        后4位是对象的分代年龄
	        后1位biased_lock 偏向锁标志
	        最后2位lock 锁标志
	        64 bits:
              --------
              unused:25 hash:31 -->| unused:1   age:4    biased_lock:1 lock:2 (normal object)
              JavaThread*:54 epoch:2 unused:1   age:4    biased_lock:1 lock:2 (biased object)
              PromotedObject*:61 --------------------->| promo_bits:3 ----->| (CMS promoted object)
              size:64 ----------------------------------------------------->| (CMS free block)

              unused:25 hash:31 -->| cms_free:1 age:4    biased_lock:1 lock:2 (COOPs && normal object)
              JavaThread*:54 epoch:2 cms_free:1 age:4    biased_lock:1 lock:2 (COOPs && biased object)
              narrowOop:32 unused:24 cms_free:1 unused:4 promo_bits:3 ----->| (COOPs && CMS promoted object)
              unused:21 size:35 -->| cms_free:1 unused:7 ------------------>| (COOPs && CMS free block)
             [ptr             | 00]  locked             ptr points to real header on stack
             [header      | 0 | 01]  unlocked           regular object header
             [ptr             | 10]  monitor            inflated lock (header is wapped out)
             [ptr             | 11]  marked             used by markSweep to mark an object

	    2.指向类信息的指针(4字节或者8字节-->32位和64位操作系统) --> 对应到方法区里面存入的类信息(字段的访问修饰符号、方法定义信息、方法字节码、常量、静态变量等)的地址
	    3.数组长度(如果该对象是数组对象，则4字节保存长度，否则没有)
	2.实例数据
	3.对齐填充字节

	指针压缩(1.6默认是开启的，关闭-XX:-UseCompressedOops) 注：指针压缩不能压缩mark word，指向非堆（Heap）的对象指针，局部变量、传参、返回值、NULL指针
    由于有对齐填充，则不管什么地址都是以000结尾，这个时候可以把地址值后3去掉补充到，这个时候相当与多了3位，于是：4*8+3=35位；所以有4G*2^3 = 32G 个地址。
    举例 0000 0000 0000 0000 0000 0000 0000 1000 --> (000) 0000 0000 0000 0000 0000 0000 0000 1000 做地址映射


Spring
	1.创建容器：
	ClassPathXmlApplicationContext：是xml方式。
	AnnotationConfigApplicationContext：是注解方式。

	new容器，构造：
		AnnotationConfigApplicationContext应该调用传入Class... annotatedClasses (注解配置类，可以传入多个)对象的构造；
			// 隐式调用父类的无参构造，super()。
				GenericApplicationContext()
					// 隐式调用父类的无参构造，super() --> AbstractApplicationContext()创建一个资源解析器。
					this.beanFactory = new DefaultListableBeanFactory(); --> 创建出一个默认容器。里面设置了一些忽略初始化bean的Class。
			this()
				AnnotatedBeanDefinitionReader --> 6个默认的BeanPostProcessor被注册到beanDefinitionMap：ConfigurationClassPostProcessor(重要的，BeanPostProcessor、BeanFactoryPostProcessor都实现了)
				ClassPathBeanDefinitionScanner --> bean的扫描类
			register()
				用于注册需要初始化的bean --> 放入beanDefinitionMap
			refresh()
				prepareRefresh()
					准备容器：设置开始时间，创建环境变量。
				prepareBeanFactory()
					准备bean工厂的上下文，如设置ClassLoader，以及添加后置处理器：ApplicationContextAwareProcessor、ApplicationListenerDetector、LoadTimeWeaverAwareProcessor
				postProcessBeanFactory()
					给子容器扩展
				invokeBeanFactoryPostProcessors()
					实例化，注册所有 BeanFactoryPostProcessor的bean；
				registerBeanPostProcessors()
					实例化并注册所有 BeanPostProcessor Bean

				finishBeanFactoryInitialization()
					preInstantiateSingletons()
						1.先遍历beanNames，然后通过beanName去beanDefinitionMap获取bean的定义信息。
						2.判断Bean 是否是抽象的、单例的、懒加载的；是否是FactoryBean类型(再判断是否急于初始化)。
						3.再getBean(beanName)
							3.1doGetBean：通过getSingleton(beanName)检查bean是否存在(1.正在创建、已经完成创建)
								getSingleton(beanName, ObjectFactory)真正的单例bean获取。
								createBean()
								doCreatBean()
								createBeanInstance()
								populateBean()
								initializeBean()：执行初始化方法(init())，beanPostProcessor 会进行 前置before方法、后置after方法。
								而代理对象也在initializeBean方法里面的 前置和后置 里面进行代理的。(AspectJAwareAdvisorAutoProxyCreator)


Mybatis
	SqlSessionFactoryBuilder：通过XMLConfigBuilder.parseConfiguration()对config文件进行解析；通过MapperBuilder解析mapper文件XML。统一封装成Configuration对象
	SqlSessionFactory：把Configuration对象设置到里面。通过openSession()获取到SqlSession。
	SqlSession：通过statement，从Configuration里面获取到MappedStatement。然后SqlSession里面的Executor属性通过MappedStatement获取对应的数据执行的Statement，和通过Configuration获取到的sql进行查询数据库操作(中间会把条件组合得到一个缓存key，判断Mybatis缓存里面是否有数据)。


Mysql
	权限表：user、db、table_priv、columns_priv、host
	binlog三种录入格式
		1.statement：每一条会修改的数据的sql都会记录在binlog中。不需要记录每一行的变化，减少日志量，节约io，提高性能。
		2.row：不记录sql语句上下文相关信息，仅保存那条记录被修改。记录单元为每一行的改动。(此外，新版的MySQL中对row级别也做了一些优化，当表结构发生变化的时候，会记录语句而不是逐行记录。)
		3.mixed：一种折中的方案，普通操作使用statement记录，当无法使用statement的时候使用row。
	存储引擎
		InnoDB
			提供对数据库ACID事务的支持，并且还提供了行级锁、外键约束。
		MyISAM
			不支持事务，也不支持行级锁、外键约束。
		区别和联系							MyISAM									InnoDB
			存储结构						每张表被存放在三个文件：frm-表格		frm-表格式定义、idb-存储数据和索引。
											式定义、MYD-数据文件、MY-索引文件。
			存储空间						MyISAM可被压缩，存储空间较小。			InnoDB的表需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引。
			可移植性、备份及恢复			数据和索引是映射关系，备份方便			通过 mysqldump、binlog、copy file 数据较大时很多慢。
			文件格式
			记录存储顺序					按记录插入顺序保存						按主键大小有序插入
			外键							不支持									支持
			事务							不支持									支持
			锁支持							表级锁定								行级锁定、表级锁定，锁定力度小并发能力高
			Select							MyISAM更优
			Insert、Update、Delete													InnoDB更优
			Select count(*)					myisam更快，因为myisam内部维护了
											一个计数器，可以直接调取。
			索引实现方式					B+树索引，myisam 是堆表					B+树索引，Innodb 是索引组织表
			哈希索引						不支持									支持
			全文索引						支持									支持

    ACID
        A：原子性，整个事务中的所有操作，要么全部完成，要么全部失败。
        C：一致性，整个事务，开始和结束之间，数据库的完整性约束没有被破坏。举例，转账:不管失败还是成功，两个账户的总金额不变。
        I：隔离性，事务之间是隔离的，一个事务不应该影响其他事务的运行效果。
        D：持久性，事务完成后，事务对数据库所做的改变，持久的保存在数据库中。

        怎么保证ACD：使用undo log、redo log。
        怎么保证CI：MVCC机制。

    undo log(文件名ibdata*；如图undo-segment.png)
        重做日志，把所有没有commit的事务回滚到事务开始前的状态，系统崩溃时，可能有些事务还没commit，在系统恢复时，通过undo log进行回滚。
        purge线程，真正进行回滚或者日志删除的。
        1.undo log用于存放数据修改 被修改前的值，假设把id=2记录的字段name="A"修改为"B"，那边undo log日志就存放name="A"的记录，当修改出现异常，
            可以使用undo log进行实现回滚操作，保证事务的一致性。
        2.为了保证事务并发操作时，在写各自的undo log时不产生冲突，InnoDB采用回滚段(roll segment一共有128个，每个1024给undo segment组成)的方式来维护undo log的并发写入和持久化。回滚段实际是一种Undo 文件组织方式，每个回滚段又有多个undo log slot。
            slot 0：预留给系统表空间。
            slot 1-32：预留给临时表空间。每次重启数据库都会重建临时表空间。
            slot33-127：如果有独立表空间，预留给undo独立表空间；如果没有，则预留给系统表空间。
        3.一条记录，会在undo log里面添加row_id、trx_id、roll_pointer三隐藏字段。roll_pointer指向上一个undo log。
            insert操作：日志类型trx_undo_insert_rec，存储undo type、undo no、table id、主键各列信息<len,value>列表等。len表示主键列占用的存储空间，value表示实际值。
            delete操作：两阶段删除，1：delete mark阶段，将记录delete_mark标识位设置为1，不会将该记录移动到垃圾链表。2：purge阶段，当该删除语句所在的事务提交之后，会有专门的线程(purge thread)来真正的把记录删除掉。就是把记录
                移动到垃圾链表(头插法)。由于阶段二是提交事务，如果回滚则考虑阶段一，innodb设计了一种trx_undo_del_mark_rec类型的undo日志，它存储 undo type、undo no、table id、old trx_id、old roll_pointer、主键各列信息<len,value>列表、索引列各列信息<pos,len,value>列表等信息。
            update操作：不更新主键的情况、更新主键的情况。
                不更新主键的情况：(存储：TRX_UNDO_UPD_EXIST_REC 的 undo 日志，它存储 undo type、undo no、table id、old trx_id、old roll_pointer、主键各列信息<len,value>列表、n_updated、被更新列更新前信息<pos, old_len, old_value>列表、索引列各列信息<pos, len, value>列表等信息。)
                1.被更新的每个列来说，如果更新前后占用存储空间不变，那么就可以直接在原记录上直接修改。
                2.被更新的列存储空间发送变化，就不能在原记录上直接修改，得先在聚簇索引中删除该记录，然后再根据更新后的值创建一条新的记录插入。
                更新主键的情况：
                1.将就旧纪录进行delete mark操作。
                2.根据更新后各列的值创建一条新记录，重新定位并将其插入到聚簇索引中。

    参考：https://www.cnblogs.com/DataArt/p/10209573.html
    redo log (文件名ib_flielog*；redo log是innodb引擎层实现的，并不是所有引擎都有。)
        组成：通过mrt生成的redo log放在大小为512字节的redo log block中，该block由log block header(12字节)、log block body、和log block trailer(4字节)组成。
            真正的信息都存储在log block body中，log block header和log block trailer存储了一些管理信息，包括以下几个信息：
            log_block_hdr_no(4)：该block的唯一标记号。
            log_block_hdr_data_len(2)：记录log大小，表示block中已经使用了多少字节，初始值为12。
            log_block_first_rec_group(2)：这个block里面第一个第一个mtr生成的第一条redo log的偏移量。
            log_block_checkpoint_no(4)：checkpoint的序号。
        1.每次更新操作都要写入磁盘，然后磁盘要找到对应记录，然后再更新。整个过程io成本、查找成本都很高。解决方案：WAL技术，先写日志，再写磁盘。
        2.redo log的大小是固定的，在mysql中可以通过修改配置参数innodb_log_files_in_group和innodb_log_file_size配置日志文件的数量和每个日志文件的大小。
        3.redo log采用循环写的方式记录，当写到结尾时，会回到开头循环写日志。
        如图：redolog.png
        例子：当一条记录需要更新，InnoDB引擎就会把记录写到redo log里面，并更新内存，这个时候更新就算完成了。同时，InnoDB引擎会在适当的时候，
        将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做的。InnoDB的redo log是固定大小的，比如可以配置为一组4个文件，每个文件的
        大小是1GB，那么总共就可以记录4GB的操作。从头开始写，写到末尾就有回到开头循环写。类似一个环状，有check point、write pos。
        write pos：表示日志当前记录的位置，当ib_logfile_4写满后，会从ib_logfile_1从头开始记录；
        check point：表示将日志记录的修改写进磁盘，完成数据落盘，数据落盘后checkpoint会将日志上的相关记录擦除掉，即 write pos -> check point之间的部分是redo log空着的部分，用于
        记录新的记录；check point -> write pos 之间的部分是redo log待落盘的数据修改记录。当write pos追上check point时，得先停下记录，先推动check point向前Dion给，空出位置记录新的日志。
        有了 redo log，当数据库发生宕机后，可通过redo log将未落盘的数据恢复，即保证已经提交的事务记录不会丢失。
        4.(图flush.png、flush-pro.png) redo log写入有三种模式，0、1、2；redo_log_buffer、buffer_free(os)、redo log文件；0：写入redo_log_buffer然后每隔1秒刷新到buffer_free(os)、再调用os(fsync())刷新到redo log。
            1(默认)：直接写入通过os buffer，并调用fsync()刷到磁盘。2：从log_buffer写入os buffer，然后每秒调用fsync()刷新到磁盘。

    mvcc：基于undo log实现的
        当进行查询或者修改操作时，会生成一个readView(有个列表存储当前活跃的读写事务，就是begin还未提交的事务。)。只查找事务版本早于自己的数据行，还有不存在列表中的。

    慢查询日志
        开启慢查询日志：my.cnf
        [mysqld]
        long_query_time=2
        #5.5以前版本配置如下选项
        log-slow-queries="mysql_slow_query.log"
        #5.5及以上版本配置如下选项
        slow-query-log=On
        slow_query_log_file="mysql_slow_query.log"

        找到文件：使用mysql自带的工具
        1.得到返回记录集最多的10个SQL
        /usr/bin/mysqldumpslow -s r -t 10 mysql_slow_query_log
        2.得到访问次数最多的10个SQL
        /usr/bin/mysqldumpslow -s c -t 10 mysql_slow_query_log
        3.得到按照时间排序的前10条里面含有左连接的查询语句
        /usr/bin/mysqldumpslow -s t -t 10 -g "left join" mysql_slow_query_log


    锁
        分类
        1.表级锁
            对整张表加锁。开销小，加锁快；不会出现死锁；锁的粒度大，锁发生冲突的概率最低，并发度也最高。
        2.行级锁
            对某行记录加锁，开销大，加锁慢；会出现死锁，锁的粒度最小，发生锁冲突的概率最低，并发度也最高。
        3.页面锁
            开销和加锁时间介于表锁和行锁之间；会出现死锁；锁的粒度介于表锁和行锁之间，并发度一般。

        myISAM                      InnoDB
表级锁     (1)                         (2)
        表级别共享锁                 意向共享锁
        表级别排它锁                 意向排它锁
        concurrent_insert优化       表锁实现方式
        low_priority_updates优化    优化建议
行级锁         (3)                     (4)
        无                          行级共享锁
                                    行级排它锁
                                    间隙锁
                                    死锁的定义、检测、查询、恢复和避免
                                    事务隔离
                                    优化建议

        (1)：
        1.对MyISAM表的读操作(共享锁/S锁)，不会阻塞其他进程对同一表的读请求，但会阻塞对其的写请求。当读锁释放后，才会指向其他进程的写操作。
        2.对MyISAM表的写操作(排它锁/X锁)，会阻塞其他进程对同一表的读写请求，当该锁释放后，才会执行其他进程的读写操作。

        在使用MyIASM存储引擎时，执行sql语句，会自动为SELECT语句加上共享锁，为UDI(更新、删除、插入)操作加上排它锁。
            由于这个特性在多进程并发的插入同一张表的时候，就会因为排他锁而进行等待。可以通过配置concurrent_insert系统变量，来控制其并发的插入行为。
            concurrent_insert=0；不允许并发插入。
            concurrent_insert=1；如果MyISAM表中没有空洞(即表中没有被删除的行)，允许一个进程读表时，另一个进程向表的尾部插入记录(Mysql默认设置)。
            concurrent_insert=2；无论MyISAM表中有没有空洞，都允许在表尾并发插入记录。

        当一个进程请求某个 MyISAM 表的读锁，另一个进程也请求同一表的写锁。
        即使读请求先到达，写请求后到达，写请求也会插到读请求之前。因为 MySQL 的默认设置认为，写请求比读请求重要。
        可以通过low_priority_updates 来调节读写行为的优先级：
            数据库以读为主，要优先保证查询性能，设置为 1 ；读优先级别高于写优先级。
            数据库以写为主，不用设置。

        (2)：
        1.意向共享锁(IS)：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前，必须先取得该表的IS锁。
        2.意向排他锁(IX)：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前，必须先取得该表的IX锁。
        注：表锁是系统自己加上的。对于Update、Delete、Insert语句，InnoDB会自动给数据集加排他锁。

        演示(表级别的锁)：一个user表，只有id、name字段；id不是主键、也没有任何索引。当窗口1执行完update语句；窗口2开始执行，会阻塞。直到窗口1提交并释放锁。
            1)窗口1
            begin;
            update user set name = "张三1" where id = 1 ;
            commit;
            2)窗口2
            begin;
            update user set name = "李四1" where id =2;
            commit;

        (4)：这部分使用的比较多（行锁是加在索引上的）
        共享锁(S；lock in share mode)：当一个事务读取一条记录的时候，不会阻塞其他事务对同一记录的读请求，但会阻塞对其的写请求。当锁释放后，才会执行其他事务的写操作。
        排他锁(X；for update)：当一个事务对一条记录进行写操作时，会阻塞其他事务对同一表的读写操作，当该锁释放后，才会执行其他事务的读写操作。

        行锁的实现
             演示：一个user1表，只有id、name字段；id是主键。当窗口1执行完update语句；窗口2开始执行，不会阻塞。如果更新的记录和窗口1一样的话 也会阻塞。可以通过innodb_lock_wait_timeout设置等待锁的时间
             1)窗口1
             begin;
             update user set name = "张三1" where id = 1 ;
             commit;
             2)窗口2
             begin;
             update user set name = "李四1" where id =2;
             commit;

        锁的关系，如图：mysql锁.png

        间隙锁：当对一个范围内的记录加锁的时候，我们称之为间隙锁。当使用范围条件索引数据时，InnoDB 会对符合条件的数据索引项加锁。
            对于键值在条件范围内但并不存在的记录，叫做"间隙(GAP)"，InnoDB 也会对这个"间隙"加锁，这就是间隙锁。间隙锁和行锁合称(Next-Key锁)。
            如sql：select * from table_name id > 10 for update;
            使用间隙锁的目的，防止幻读，对于上面的sql，当有记录插入且id大于10；再次查询的时候就会多出记录。

        死锁：当两个事务都需要获取对方持有的排他锁才能继续完成任务，这种互相等待对方释放资源的情况就是死锁。
            演示：
                1)窗口1
                begin;                                               --1
                update user set name = "张三1" where id =1;          --3
                update user set name = "李四11" where id =2;         --5     // 阻塞
                commit;

                2)窗口2
                begin;                                              --2
                update user set name = "李四1" where id =2;         --4
                update user set name = "张三11" where id =1;        --6     // Deadlock found when trying to get lock; try restarting transaction
                commit;

            检测死锁：InnoDB存储引擎能检测到死锁的循环依赖，并立即返回一个错误。
            死锁恢复：死锁发生以后，只有部分或完全回滚其中一个事务，才能打破死锁。
            InnoDB是将持有最少行级排他锁的事务回滚。在应用程序设计时，必须考虑处理死锁，多数情况下重新执行因死锁回滚的事务即可。

            避免死锁：在事务中如果有更新、查询，直接申请排他锁，？？

    缓存机制

    索引：可以说索引是Mysql的灵魂，是平时进行查询的利器。
        分析：一条查询语句是如何执行的；
            1.当执行SQL语句时，应用程序会连接到相应的数据库服务器，然后服务器对SQL进行处理。
            2.(查询缓存)；接着数据库服务会先去查询是否有该SQL语句的缓存，Key是查询的语句，value是查询的结果。如果你的查询能直接命中，就会直接从缓存中拿出value来返回客户端。注：查询不会被解析、不会生成执行计划、不会被执行。
            3.(查询优化处理，生成执行计划)；
                sql：预编译解决注入问题
                    prepare ins from 'select * from user where id = ?';
                    set @a = '1';
                    set @b = '1 or 1=1';
                    execute ins using @a; // 正确返回id='1'这条记录
                    execute ins using @b; // 没有匹配上
                    注意：如果@a = 1 and or 1=1  这个会把@a设置为1。

                解析SQL：生成解析树，验证关键字如select、where、left join等，是否正确。
                预处理：进一步检查解析树是否合法，如检查数据表和列是否存在，验证用户权限等。
                优化SQL：决定使用那个索引，或者在多个表相关联的时候决定表的连接顺序。紧接着，将SQL语句转成执行计划。
            4.将查询结果返回客户端
              数据库服务器将查询结果返回给客户端。(如果查询可用缓存，mysql也会将结果缓存)

        分类：
            存储结构上：
            1.Btree索引(B+树，B树)
            2.哈希索引
            3.full-index(全文索引)
            4.RTree

            应用层次上：
            1.普通索引：即一个索引只含单个列，一个表可以有多个单列索引。
            2.唯一索引：索引列的值必须唯一，但运行有空值。
            3.复合(组合)索引：一个索引包含多个索引列。

            表记录的排序顺序和索引的排列顺序是否一致
            1.聚集(簇)索引：(就是以主键创建的索引。)；表记录的排列顺序和索引的排列顺序 一致。
                聚集索引表记录的排列顺序和索引的排列顺序一致，所以查询效率快，因为只要找到第一个索引值记录，其余的连续性的记录在物理表中也会连续存放，一起就可以查询到。
                缺点：新增比较慢，因为为了保证表记录的物理顺序和索引顺序一致，在记录插入的时候，会对数据页重新排序。
            2.非聚集(簇)索引：(就是以非主键创建的索引（也叫做二级索引）。)；表记录的排序顺序和索引的排序顺序 不一致。
                索引的逻辑顺序与磁盘上的物理存储顺序不同，非聚集索引在叶子节点存储的是主键和索引列，当我们使用非聚集索引查询数据时，需要拿到叶子上的主键再去表中查想要的数据。这个过程就是回表。

            假设要查询某个区间的数据，我们只需要拿到区间的起始值，然后在树中进行查找。找到对应叶子节点数据，遍历下面的数据页。

        索引的数据结构
            哈希索引：(hash结构)
                局限性
                1.没办法通过索引进行排序。
                2.不能进行多字段的查询
                3.子啊有大量重复键的情况下，效率低
                4.不支持范围查询
            B+树：如图b+树.png


    主从

    分库分表

    崩溃恢复(http://mysql.taobao.org/monthly/2015/04/01/)||http://mysql.taobao.org/monthly/
        当实例从崩溃中恢复时，需要将活跃的事务从undo中提取出来，对于ACTIVE状态的事务直接回滚，对于Prepare状态的事务，如果该事务对应的binlog已经记录，则提交，否则回滚事务。
        实现的流程也比较简单，首先先做redo (recv_recovery_from_checkpoint_start)，undo是受redo 保护的，因此可以从redo中恢复（临时表undo除外，临时表undo是不记录redo的）。

        在redo日志应用完成后，初始化完成数据词典子系统（dict_boot），随后开始初始化事务子系统（trx_sys_init_at_db_start），undo 段的初始化即在这一步完成。

        在初始化undo段时(trx_sys_init_at_db_start -> trx_rseg_array_init -> ... -> trx_undo_lists_init)，会根据每个回滚段page中的slot是否被使用来恢复对应的undo log，读取其状态信息和类型等信息，创建内存结构，并存放到每个回滚段的undo list上。

        当初始化完成undo内存对象后，就要据此来恢复崩溃前的事务链表了(trx_lists_init_at_db_start)，根据每个回滚段的insert_undo_list来恢复插入操作的事务(trx_resurrect_insert)，根据update_undo_list来恢复更新事务(tex_resurrect_update)，如果既存在插入又存在更新，则只恢复一个事务对象。另外除了恢复事务对象外，还要恢复表锁及读写事务链表，从而恢复到崩溃之前的事务场景。

        当从Undo恢复崩溃前活跃的事务对象后，会去开启一个后台线程来做事务回滚和清理操作（recv_recovery_rollback_active -> trx_rollback_or_clean_all_recovered），对于处于ACTIVE状态的事务直接回滚，对于既不ACTIVE也非PREPARE状态的事务，直接则认为其是提交的，直接释放事务对象。但完成这一步后，理论上事务链表上只存在PREPARE状态的事务。

        随后很快我们进入XA Recover阶段，MySQL使用内部XA，即通过Binlog和InnoDB做XA恢复。在初始化完成引擎后，Server层会开始扫描最后一个Binlog文件，搜集其中记录的XID（MYSQL_BIN_LOG::recover），然后和InnoDB层的事务XID做对比。如果XID已经存在于binlog中了，对应的事务需要提交；否则需要回滚事务。

        Tips：为何只需要扫描最后一个binlog文件就可以了？ 因为在每次rotate到一个新的binlog文件之前，总是要保证前一个binlog文件中对应的事务都提交并且sync redo到磁盘了，也就是说，前一个binlog文件中的事务在崩溃恢复时肯定是出于提交状态的。


Redis
	1.持久化
		RDB
			fork相同子进程，把数据写入到临时文件，当持久化结束，把临时文件替换成上次持久化好的文件。(问题：会有丢失数据的情况)
		AOF
			会将修改数据 命令，同步写入aof文件，当aof文件过大就会进行重写，就是fork子进程，进行读取aof文件，然后写一个临时文件(比如有set k1 vl和del k1、这两条抵消)，最后替换原文件。
	2.集群模式
		主从集群
		    一个主节点进行读写请求，多个从节点(复制主节点数据)进行读请求。出现问题：单点故障，数据重复。
		哨兵集群
		    一个主节点和多个从节点，通过哨兵节点进行监控主机点状态，当主节点单机，可以进行从节点晋升为主节点(选举机制)。但是在选举过程中，整个服务不可用。出现问题：切换主节点会造成一段时间不可用，数据重复。
		cluster集群
		    类似与多个哨兵集群，存储数据的时候，通过key%16384 找到对应槽位，把数据插入。当一个集群挂了，剩余集群还是可以工作。
	3.常见问题
		缓存穿透
			数据库中本来就没有的数据：解决方案，布隆过滤器、存储空数据设置很短的过期时间(防止很多值为null的key存在)。
		缓存击穿
			缓存中不存在的数据，然后有个高并发请求。导致大量请求落到mysql上：解决方案，分布式锁。
		缓存雪崩
			同一时间很多key都失效了，导致大量请求落到mysql上：解决方案，把key过期时间设置为不同时间段。
		数据库和缓存怎么保证一致性
			延时双删：写库前，先删除缓存，再写数据库。休眠一个主从数据延时的时间+(读请求耗时)，然后再次进行删除缓存。会存在一个问题，数据库写成功了，删除缓存失败。定义重试策略。
	4.单线程为什么快
		基于内存的读写速度快、单线程减少上下文切换时间、使用多路复用技术，可以处理并发的连接，非阻塞IO内部采用epoll+自己实现的简单事件框架。epoll中的读、写、关闭、连接都转化为事件。
		然后利用多路复用的特性，不在io上浪费一点时间。


MQ：
	好处：异步、解耦、削峰填谷
	造成的问题：消息重复消费、消息丢失、甚至消息顺序性的问题。

	解决方案
	消息丢失：主要分为，生产端丢数据、MQ丢数据、消费端丢数据。
	生产端丢数据：
		使用事务消息，生产者开起，MQ没有收到的话会发送一个异常，收到则提交事务，性能低。主流通过Confirm机制，每次写消息分配一个唯一id，当MQ收到消息 会发送一ACK 给生产端。如果没有收到，则进行回调nack接口。
	MQ丢数据：
		持久化没成功，mq宕机了。不太可能
	消费端丢数据：
		消费者在代码里面手动ack。

    RocketMQ
        主要角色：
        Producer：消息发布角色
        Consumer：消息消费角色
        NameServer cluster：一个非常简单的topic路由注册中心，类似于zookeeper，支持Broker的动态注册与发现。
        Broker cluster：负责消息的存储、投递、和查询以及服务高可用保证，为了实现这些功能，broker包含以下几个模块
            Remoting module：整个Broker的实体，负责处理来自client端的请求。
            Client Manager：负责管理客户端(Producer/Consumer)和委会Consumer的Topic订阅信息。
            Store Service：提供方便简单的API接口处理消息存储到物理硬盘和查询功能。
            HA Service：高可用服务，提供Master Broker和Slave Broker之间的数据同步功能。
            Index Service：根据特定的Message key对投递到Broker的消息进行索引服务，以提供消息的快速查询。

        一些问题
            生产端丢数据：
                同步发送消息：发送一条消息，生产者轮询查mq是否收到，没有就重发，有就确认。性能较低。
                事务消息：
                1.首先发送half消息，然后 mq收到的话，会回一个确认，或者其他情况就失败。(相比于同步发送消息，这里不需要轮询确认)。
                2.处理业务
                3.根据业务成功或者失败，进行commit/rollback。
                4.如果mq没有收到commit/rollback；则进行轮询访问生产者。15次

            MQ丢数据：

            消费端丢数据：

        Broker存储架构
            三文件
            1.CommitLog：消息主题以即元数据的存储主体，存储Producer端写入的消息主体内容，消息内容不是定长的。单个文件大小默认1G，文件名长度为20位，左边补零，剩余未起始偏移量。
                如：00000000000000000000代表了第一个文件，起始偏移量为0，文件大小为1G=1073741824；当第一个文件写满了，第二个文件为
                    00000000001073741824，起始偏移量为1073741824   以此类推。消息主要是顺序写入日志文件，当文件满了，写入下一个文件；
            2.ConsumeQueue：消息消费队列，引入的目的主要是提高消息消费的性能，由于由于RocketMQ是基于主题topic的订阅模式，消息消费是针对主题进行的，如果要遍历commitlog文件中根据topic检索消息是非常低效的。
                Consumer即可根据ConsumeQueue来查找待消费的消息。其中，ConsumeQueue（逻辑消费队列）作为消费消息的索引，保存了指定Topic下的队列消息在CommitLog中的起始物理偏移量offset，消息大小size和消息Tag的HashCode值。
                consumequeue文件可以看成是基于topic的commitlog索引文件，故consumequeue文件夹的组织方式如下：topic/queue/file三层组织结构，具体存储路径为：$HOME/store/consumequeue/{topic}/{queueId}/{fileName}。
                同样consumequeue文件采取定长设计，每一个条目共20个字节，分别为8字节的commitlog物理偏移量、4字节的消息长度、8字节tag hashcode，单个文件由30W个条目组成，可以像数组一样随机访问每一个条目，每个ConsumeQueue文件大小约5.72M；

            3.IndexFile：IndexFile（索引文件）提供了一种可以通过key或时间区间来查询消息的方法。Index文件的存储位置是：$HOME \store\index${fileName}，文件名fileName是以创建时的时间戳命名的，固定的单个IndexFile文件大小约为400M，
                    一个IndexFile可以保存 2000W个索引，IndexFile的底层存储设计为在文件系统中实现HashMap结构，故rocketmq的索引文件其底层实现为hash索引。
                总结：
                    RocketMQ采用的是混合型的存储结构，即为Broker单个实例下所有的队列共用一个日志数据文件（即为CommitLog）来存储。
                    RocketMQ的混合型存储结构(多个Topic的消息实体内容都存储于一个CommitLog中)针对Producer和Consumer分别采用了数据和索引部分相分离的存储结构，
                    Producer发送消息至Broker端，然后Broker端使用同步或者异步的方式对消息刷盘持久化，保存至CommitLog中。
                    只要消息被刷盘持久化至磁盘文件CommitLog中，那么Producer发送的消息就不会丢失。正因为如此，Consumer也就肯定有机会去消费这条消息。
                    当无法拉取到消息后，可以等下一次消息拉取，同时服务端也支持长轮询模式，如果一个消息拉取请求未拉取到消息，Broker允许等待30s的时间，
                    只要这段时间内有新消息到达，将直接返回给消费端。这里，RocketMQ的具体做法是，
                    使用Broker端的后台服务线程—ReputMessageService不停地分发请求并异步构建ConsumeQueue（逻辑消费队列）和IndexFile（索引文件）数据。

            页缓存与内存映射
                页缓存是OS对文件的缓存，用于加速对文件的读写。一般来说，程序对文件进行顺序读写的速度几乎接近于内存的读写速度，主要原因是OS使用页缓存机制对读写访问操作进行了性能优化，将一部分内存用作PageCache。
                对于数据写入，OS会先写入至Cache内，随后通过异步的方式由 pdflush内核线程 将Cache内的数据刷盘至物理磁盘上。
                对于数据读取，如果异常读取文件时出现未命中PageCache的情况，OS从物理磁盘上访问读取文件的同时，会顺序对其他相邻块的数据文件进行预读取。

                在RocketMQ中，ConsumeQueue逻辑消费队列存储的数据较少，并且是顺序读取，在page cache机制的预读取作用下，Consume Queue文件的读性能几乎接近读内存，即使在有消息堆积情况下也不会影响性能。
                而对于CommitLog消息存储的日志数据文件来说，读取消息内容时候会产生较多的随机访问读取，严重影响性能。如果选择合适的系统IO调度算法，比如设置调度算法为“Deadline”（此时块存储采用SSD的话），随机读的性能也会有所提升。

                另外，RocketMQ主要通过MappedByteBuffer对文件进行读写操作。其中，利用了NIO中的FileChannel模型将磁盘上的物理文件直接映射到用户态的内存地址中
                （这种Mmap的方式减少了传统IO将磁盘文件数据在操作系统内核地址空间的缓冲区和用户应用程序地址空间的缓冲区之间来回进行拷贝的性能开销），
                将对文件的操作转化为直接对内存地址进行操作，从而极大地提高了文件的读写效率（正因为需要使用内存映射机制，故RocketMQ的文件存储都使用定长结构来存储，方便一次将整个文件映射至内存）。

            消息刷盘：(如图：刷盘.png)
                1.同步刷盘
                    只有在消息真正持久化至磁盘后RocketMQ的Broker端才会真正返回给Producer端一个成功的ACK响应。同步刷盘对MQ消息可靠性来说是一种不错的保障，但是性能上会有较大影响，一般适用于金融业务应用该模式较多。
                2.异步刷盘
                    能够充分利用OS的PageCache的优势，只要消息写入PageCache即可将成功的ACK返回给Producer端。消息刷盘采用后台异步线程提交的方式进行，降低了读写延迟，提高了MQ的性能和吞吐量。

        MQ的通信机制

RPC：
    调用流程(如图：rpc.png)
        1) 服务消费方（client）调用以本地调用方式调用服务；

        2) client stub接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体；

        3) client stub找到服务地址，并将消息发送到服务端；

        4) server stub收到消息后进行解码；

        5) server stub根据解码结果调用本地的服务；

        6) 本地服务执行并将结果返回给server stub；

        7) server stub将返回结果打包成消息并发送至消费方；

        8) client stub接收到消息，并进行解码；

        9) 服务消费方得到最终结果。
        RPC的目标就是要2~8这些步骤都封装起来，让用户对这些细节透明。

    消息编码和解码

    网络通信


	
	
	
计算机网络、协议相关
    协议分层模型：七层、五层、四层
    OSI：给网络协议分层标准提供理论
    1.物理层
    2.数据链路层
    3.网络层
    4.传输层
    5.会话层
    6.表示层
    7.应用层

    tcp/ip：制定网络协议分层的标准，可以理解为OSI的实现
                            数据包的角度
    1.链路层                 以太网首部；ip首部；tcp首部；[http数据、其他应用层数据]
    2.网络层                 ip首部；tcp首部；[http数据、其他应用层数据]
    3.传输层                 tcp首部；[http数据、其他应用层数据]
    4.应用层                 [http数据、其他应用层数据]

    ip协议：是无连接的协议，不会占用两个通信计算机的通信线路，负责将每个数据包路由到指定计算机。

    传输控制协议tcp简介：
    1.面向连接的、可靠的、基于字节流的传输层通信协议。
    2.将应用层的数据流分割成报文并发送给目标节点的TCP层。
    3.数据包都有序号，对方收到则发送ACK确认，未收到则重传。
    4.使用校验和来检验数据在传输过程中是否有误。

    tcp报文头部结构：
    source port(2字节)             Destination port(2字节)
                sequence Number(4字节)
                Acknowledgment Number(4字节)
    Offset(1字节)    Reserved(1字节)      TCP Flags(cwr、ece、urgent、ack、push、reset、syn、fin)(c e u a p r s f；2字节)     Window(2字节)
    Checksum()                    Urgent Pointer
            TCP Options(variable length、optional)
        user data

    TCP Flags(cwr、ece、urgent、ack、push、reset、syn、fin)介绍
    URG：紧急指针标志
    ACK：确认序号
    psh：push标志
    RST：重置连接标志
    SYN：同步序列号，用于建立连接过程
    FIN：finish标志，用于释放连接。

    window窗口：指滑动窗口的大小，用来告知接收端的缓存大小。
    checksum：接收和发送校验。

        tcp的三次握手：
        client                                          server
    状态syn-sent      --SYN=1，seq=x-->                    listen
      established   <--SYN=1,ACK=1,seq=y,ack=x+1--      syn-rcvd
      established   --ACK=1,seq=x+1,ack=y+1-->          established
                   <----------传输数据----------->

        tcp的四次挥手：
        client                                              server
    状态syn-send      --SYN=1


	
网络IO